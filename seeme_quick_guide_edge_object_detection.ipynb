{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_class_names(namesfile):\n",
    "    class_names = []\n",
    "    with open(namesfile, 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        class_names.append(line)\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nms_cpu(boxes, confs, nms_thresh=0.5, min_mode=False):\n",
    "    # print(boxes.shape)\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    order = confs.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        idx_self = order[0]\n",
    "        idx_other = order[1:]\n",
    "\n",
    "        keep.append(idx_self)\n",
    "\n",
    "        xx1 = np.maximum(x1[idx_self], x1[idx_other])\n",
    "        yy1 = np.maximum(y1[idx_self], y1[idx_other])\n",
    "        xx2 = np.minimum(x2[idx_self], x2[idx_other])\n",
    "        yy2 = np.minimum(y2[idx_self], y2[idx_other])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1)\n",
    "        h = np.maximum(0.0, yy2 - yy1)\n",
    "        inter = w * h\n",
    "\n",
    "        if min_mode:\n",
    "            over = inter / np.minimum(areas[order[0]], areas[order[1:]])\n",
    "        else:\n",
    "            over = inter / (areas[order[0]] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(over <= nms_thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "    \n",
    "    return np.array(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def post_processing(img, conf_thresh, nms_thresh, output):\n",
    "    # anchors = [12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401]\n",
    "    # num_anchors = 9\n",
    "    # anchor_masks = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "    # strides = [8, 16, 32]\n",
    "    # anchor_step = len(anchors) // num_anchors\n",
    "\n",
    "    # [batch, num, 1, 4]\n",
    "    box_array = output[0]\n",
    "    # [batch, num, num_classes]\n",
    "    confs = output[1]\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    if type(box_array).__name__ != 'ndarray':\n",
    "        box_array = box_array.cpu().detach().numpy()\n",
    "        confs = confs.cpu().detach().numpy()\n",
    "\n",
    "    num_classes = confs.shape[2]\n",
    "\n",
    "    # [batch, num, 4]\n",
    "    box_array = box_array[:, :, 0]\n",
    "\n",
    "    # [batch, num, num_classes] --> [batch, num]\n",
    "    max_conf = np.max(confs, axis=2)\n",
    "    max_id = np.argmax(confs, axis=2)\n",
    "\n",
    "    t2 = time.time()\n",
    "\n",
    "    bboxes_batch = []\n",
    "    for i in range(box_array.shape[0]):\n",
    "       \n",
    "        argwhere = max_conf[i] > conf_thresh\n",
    "        l_box_array = box_array[i, argwhere, :]\n",
    "        l_max_conf = max_conf[i, argwhere]\n",
    "        l_max_id = max_id[i, argwhere]\n",
    "\n",
    "        bboxes = []\n",
    "        # nms for each class\n",
    "        for j in range(num_classes):\n",
    "\n",
    "            cls_argwhere = l_max_id == j\n",
    "            ll_box_array = l_box_array[cls_argwhere, :]\n",
    "            ll_max_conf = l_max_conf[cls_argwhere]\n",
    "            ll_max_id = l_max_id[cls_argwhere]\n",
    "\n",
    "            keep = nms_cpu(ll_box_array, ll_max_conf, nms_thresh)\n",
    "            \n",
    "            if (keep.size > 0):\n",
    "                ll_box_array = ll_box_array[keep, :]\n",
    "                ll_max_conf = ll_max_conf[keep]\n",
    "                ll_max_id = ll_max_id[keep]\n",
    "\n",
    "                for k in range(ll_box_array.shape[0]):\n",
    "                    bboxes.append([ll_box_array[k, 0], ll_box_array[k, 1], ll_box_array[k, 2], ll_box_array[k, 3], ll_max_conf[k], ll_max_conf[k], ll_max_id[k]])\n",
    "        \n",
    "        bboxes_batch.append(bboxes)\n",
    "\n",
    "    t3 = time.time()\n",
    "\n",
    "    # print('-----------------------------------')\n",
    "    # print('       max and argmax : %f' % (t2 - t1))\n",
    "    # print('                  nms : %f' % (t3 - t2))\n",
    "    # print('Post processing total : %f' % (t3 - t1))\n",
    "    # print('-----------------------------------')\n",
    "    \n",
    "    return bboxes_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_full_path = detection_model[\"active_version_id\"] + \".onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession(onnx_full_path)\n",
    "\n",
    "IN_IMAGE_H = session.get_inputs()[0].shape[2]\n",
    "IN_IMAGE_W = session.get_inputs()[0].shape[3]\n",
    "\n",
    "image_src = cv2.imread(\"bus-car-person.jpg\")\n",
    "\n",
    "resized = cv2.resize(image_src, (IN_IMAGE_W, IN_IMAGE_H), interpolation=cv2.INTER_LINEAR)\n",
    "img_in = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "img_in = np.transpose(img_in, (2, 0, 1)).astype(np.float32)\n",
    "img_in = np.expand_dims(img_in, axis=0)\n",
    "img_in /= 255.0\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "\n",
    "outputs = session.run(None, {input_name: img_in})\n",
    "\n",
    "boxes = post_processing(img_in, 0.4, 0.6, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = detection_model[\"active_version_id\"] + \".names\"\n",
    "class_names = load_class_names(labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0074151456, 0.007669747, 0.3948107, 0.9739917, 0.9312626, 0.9312626, 0]\n",
      "person\n",
      "[0.63776255, 0.01903963, 0.99418163, 0.9847417, 0.9092924, 0.9092924, 0]\n",
      "person\n",
      "[0.29356784, 0.22734743, 0.33088827, 0.31162006, 0.8798908, 0.8798908, 2]\n",
      "car\n",
      "[0.77916926, 0.18809426, 0.8264917, 0.3314556, 0.5911089, 0.5911089, 2]\n",
      "car\n",
      "[0.33751625, -0.00433293, 0.76922274, 0.6129248, 0.95931864, 0.95931864, 5]\n",
      "bus\n"
     ]
    }
   ],
   "source": [
    "for box in boxes[0]:\n",
    "    print(box)\n",
    "   \n",
    "    print(class_names[box[6]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_predict(model, img):\n",
    "    onnx_full_path = model[\"active_version_id\"] + \".onnx\"\n",
    "    session = onnxruntime.InferenceSession(onnx_full_path)\n",
    "\n",
    "    IN_IMAGE_H = session.get_inputs()[0].shape[2]\n",
    "    IN_IMAGE_W = session.get_inputs()[0].shape[3]\n",
    "\n",
    "    image_src = cv2.imread(img)\n",
    "\n",
    "    resized = cv2.resize(image_src, (IN_IMAGE_W, IN_IMAGE_H), interpolation=cv2.INTER_LINEAR)\n",
    "    img_in = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "    img_in = np.transpose(img_in, (2, 0, 1)).astype(np.float32)\n",
    "    img_in = np.expand_dims(img_in, axis=0)\n",
    "    img_in /= 255.0\n",
    "\n",
    "    input_name = session.get_inputs()[0].name\n",
    "\n",
    "    outputs = session.run(None, {input_name: img_in})\n",
    "\n",
    "    boxes = post_processing(img_in, 0.4, 0.6, outputs)\n",
    "    \n",
    "    labels_file = model[\"active_version_id\"] + \".names\"\n",
    "    class_names = load_class_names(labels_file)\n",
    "   \n",
    "    \n",
    "    for box in boxes[0]:\n",
    "       \n",
    "        print(box)\n",
    "\n",
    "        print(class_names[box[6]])\n",
    "        print(\"------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clX6MGwv8rq2"
   },
   "source": [
    "# SeeMe.ai quick guide Object Detection at the edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVNG2OMg8rq8"
   },
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKTHwteB8rq8"
   },
   "source": [
    "## 1.1 Where to run your Jupyter Notebooks\n",
    "\n",
    "Use your preferred platfrom to run your [Jupyter Notebooks](https://jupyter.org/): \n",
    "\n",
    "* [Paperspace](https://paperspace.com)\n",
    "* [Google Colab](https://colab.research.google.com/)\n",
    "* [The official Fast.ai Docker images](https://hub.docker.com/u/fastdotai)\n",
    "* [Fast.ai Docker from SeeMe.ai](https://hub.docker.com/repository/docker/seemeai/fastai)\n",
    "* [Azure](https://azure.microsoft.com)\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "H0W2QEdF96r_"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BvxMuFNO8rq9",
    "outputId": "0fca2c50-e996-4f74-837e-6fce723e99c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0hYFJWX8rrB"
   },
   "source": [
    "## 1.2 SeeMe.ai Python SDK\n",
    "\n",
    "Install the [SeeMe SDK](https://pypi.org/project/seeme/) from the command line:\n",
    "\n",
    "```bash\n",
    "$ pip install --upgrade --no-cache-dir seeme\n",
    "```\n",
    "\n",
    "or in your Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from onnxruntime) (1.20.2)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-3.18.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: protobuf, flatbuffers, onnxruntime\n",
      "Successfully installed flatbuffers-2.0 onnxruntime-1.9.0 protobuf-3.18.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6TQfARG8rrC",
    "outputId": "d103bffc-9b04-450c-b777-8688913139ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seeme in /opt/conda/lib/python3.7/site-packages (0.13.6)\n",
      "Requirement already satisfied: requests>=2.18.4 in /opt/conda/lib/python3.7/site-packages (from seeme) (2.24.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from seeme) (0.9.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.18.4->seeme) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.18.4->seeme) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.18.4->seeme) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.18.4->seeme) (2.10)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install the SeeMe SDK from your notebook.\n",
    "!pip install --upgrade --no-cache-dir seeme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFcK3EiY8rrC"
   },
   "source": [
    "# 2. Create a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Wz5YY41B8rrD"
   },
   "outputs": [],
   "source": [
    "from seeme import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "RoqAMbyw8rrD"
   },
   "outputs": [],
   "source": [
    "cl = Client(username=\"janvdp\", apikey=\"a8b4f486-87a8-47dd-beaa-596086cfc146\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = cl.get_model('5d3dbde4-0600-43c6-9a37-d5cd259c0267')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.download_active_model(detection_model, assetType=\"onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.download_active_model(detection_model, assetType=\"names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0074151456, 0.007669747, 0.3948107, 0.9739917, 0.9312626, 0.9312626, 0]\n",
      "person\n",
      "------\n",
      "[0.63776255, 0.01903963, 0.99418163, 0.9847417, 0.9092924, 0.9092924, 0]\n",
      "person\n",
      "------\n",
      "[0.29356784, 0.22734743, 0.33088827, 0.31162006, 0.8798908, 0.8798908, 2]\n",
      "car\n",
      "------\n",
      "[0.77916926, 0.18809426, 0.8264917, 0.3314556, 0.5911089, 0.5911089, 2]\n",
      "car\n",
      "------\n",
      "[0.33751625, -0.00433293, 0.76922274, 0.6129248, 0.95931864, 0.95931864, 5]\n",
      "bus\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "yolo_predict(detection_model, \"bus-car-person.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "seeme-quick-guide-fastai-with-dataset-version.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
